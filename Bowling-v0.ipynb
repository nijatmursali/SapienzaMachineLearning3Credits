{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nijatmursali/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Dense,Conv2D,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluationforBowling:\n",
    "    def __init__(self,input_shape,action_size):\n",
    "        \n",
    "        \n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0 \n",
    "        self.learning_rate = 0.001\n",
    "        self.input_size  =  input_shape\n",
    "        self.action_size  =  action_size\n",
    "        self.model  = self.architectureforModel()\n",
    "        self.model_source =  self.sourceforModel()\n",
    "        \n",
    "        self.memory = deque(maxlen = 20)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def sourceforModel(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32,\n",
    "                              8,\n",
    "                              strides=(4, 4),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Conv2D(64,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Conv2D(64,\n",
    "                              3,\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(512, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "                           optimizer=RMSprop(lr=0.00025,\n",
    "                                             rho=0.95,\n",
    "                                             epsilon=0.01),\n",
    "                           metrics=[\"accuracy\"])\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def architectureforModel(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32,\n",
    "                              8,\n",
    "                              strides=(4, 4),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Conv2D(64,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Conv2D(64,\n",
    "                              3,\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=self.input_size,\n",
    "                              data_format=\"channels_first\"))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(512, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "                           optimizer=RMSprop(lr=0.00025,\n",
    "                                             rho=0.95,\n",
    "                                             epsilon=0.01),\n",
    "                           metrics=[\"accuracy\"])\n",
    "        \n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def pick_action(self,state): #choosing the random action\n",
    "        #if any random is less than epsilon then\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        #\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageprocessing(image):\n",
    "    processedImage  = img_to_array(image)\n",
    "    \n",
    "    \n",
    "    processedImage  = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   \n",
    "    processedImage  = cv2.resize(processedImage,(84,84))\n",
    "    processedImage  = np.expand_dims(processedImage,axis=0)\n",
    "    processedImage  = np.expand_dims(processedImage,axis=0)\n",
    " \n",
    "    \n",
    "    \n",
    "    return processedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottingValues(name):\n",
    "    gettingDatafromFile = open(\"Bowling-v0.txt\",\"r\").read()\n",
    "    iterationAppend = []\n",
    "    rewardAppend = []\n",
    "    myData  =  gettingDatafromFile.split(\"\\n\")\n",
    "    for data in myData:\n",
    "        try:\n",
    "            valueSplitting  = data.split(\",\")\n",
    "            valuereward  =  valueSplitting[1]\n",
    "            valueiteration = valueSplitting[0]\n",
    "\n",
    "            \n",
    "            iterationAppend.append(float(valueiteration))\n",
    "            rewardAppend.append(float(valuereward))\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass \n",
    "    \n",
    "    nameforImage=\"Bowling-v0.png\"\n",
    "    \n",
    "    plt.plot(iterationAppend,rewardAppend)\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Reward and Episode Diagram\")\n",
    "    plt.savefig(nameforImage, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 20, 20)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 9, 9)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 7, 7)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,681,062\n",
      "Trainable params: 1,681,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e3fa351d66a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmaxReward\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleImageViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m    352\u001b[0m         gl.glTexParameteri(gl.GL_TEXTURE_2D, \n\u001b[1;32m    353\u001b[0m             gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mtexture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_texture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtexture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mtexture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mget_texture\u001b[0;34m(self, rectangle, force_rectangle)\u001b[0m\n\u001b[1;32m    857\u001b[0m             self._current_texture = self.create_texture(Texture,\n\u001b[1;32m    858\u001b[0m                                                         \u001b[0mrectangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                                                         force_rectangle)\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_texture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mcreate_texture\u001b[0;34m(self, cls, rectangle, force_rectangle)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         self.blit_to_texture(texture.target, texture.level,\n\u001b[0;32m--> 850\u001b[0;31m                              self.anchor_x, self.anchor_y, 0, None)\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtexture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mblit_to_texture\u001b[0;34m(self, target, level, x, y, z, internalformat)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# already in, unless that's an obscure format, upside-down or the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# driver is old).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_pitch\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0x1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self, format, pitch)\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_pitch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpitch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;31m# Pitch differs in sign, swap row order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                 \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m                 \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env  = gym.make('Bowling-v0') #creating Bowling environment\n",
    "action_size  = env.action_space.n \n",
    "state_size = (1,84,84) #\n",
    "\n",
    "\n",
    "nn = evaluationforBowling(state_size,action_size)\n",
    "episodes  =  1000\n",
    "mbatchsize  =  32\n",
    "\n",
    "\n",
    "\n",
    "for eps in range(episodes):\n",
    "    observation  = env.reset()\n",
    "   \n",
    "    observation  =  imageprocessing(observation)\n",
    "       \n",
    "    done = False\n",
    "    maxReward  = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action =  nn.pick_action(observation)\n",
    "        \n",
    "        next_state, reward, done,_ =  env.step(action)\n",
    "        \n",
    "        next_state =  imageprocessing(next_state)     \n",
    "        maxReward  += reward\n",
    "        \n",
    "        observation  =  next_state\n",
    "        \n",
    "    \n",
    "    \n",
    "    if eps%10 == 0:\n",
    "        print(maxReward)\n",
    "        \n",
    "        openTxtFile  = open(\"Bowling-v0.txt\",'a')\n",
    "        openTxtFile.write(str(eps)+\",\"+str(maxReward))\n",
    "        openTxtFile.write(\"\\n\")\n",
    "        plottingValues(\"Bowling-v0\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
